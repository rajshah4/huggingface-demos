{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gh6QOr-qO4Ym"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/huggingface/education-toolkit/blob/main/02_ml-demos-with-gradio.ipynb)\n",
        "\n",
        "\n",
        "Transformers Pipeline Demo Notebook\n",
        "\n",
        "üí° **Welcome!**\n",
        "\n",
        "This notebook is a self-contained way to start using widely known Open Source technologies (`transformers`, `gradio`, etc). The core use case is building an application to search Wikipedia.  This notebook can be found at [https://bit.ly/raj_askwiki](https://bit.ly/raj_askwiki), the accompanying slides are at [****](https://github.com/rajshah4/huggingface-demos/tree/main/FinBERT).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lb65KY8VcSV8"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet transformers\n",
        "!pip install --quiet gradio\n",
        "!pip install --quiet sentence-transformers\n",
        "!pip install --quiet datasets\n",
        "import os\n",
        "import gzip\n",
        "import json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkJmA-r5L0EB"
      },
      "source": [
        "# Tutorial: Using Pretrained Models and Building Demos with Gradio ‚ö° & Hugging Face ü§ó "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_Iv1CJZPekG"
      },
      "source": [
        "**Learning goals:** The goal of this tutorial is to learn How To\n",
        "\n",
        "1. Use pre-trained models from the transformers library and that are available on the Hugging Face Hub\n",
        "2. Extract information from Pre-Trained Models\n",
        "3. Doing a similarity search\n",
        "4. Building a web demo, [Ask Wiki](https://huggingface.co/spaces/rajistics/Ask-Wiki)\n",
        "\n",
        "**Duration**: 60 minutes\n",
        "\n",
        "**Prerequisites:** Knowledge of Python and basic familiarity with machine learning \n",
        "\n",
        "**Author**: [Rajiv Shah](https://twitter.com/rajistics) (feel free to ping me with any questions about this tutorial) \n",
        "\n",
        "All of these steps can be done for free! All you need is an Internet browser and a place where you can write Python üë©‚Äçüíª"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-wtA32Tbfbd"
      },
      "source": [
        "# Let's Start by Exploring Pre-trained Models at Hugging Face Hub\n",
        "[Hugging Face Hub](https://hf.co) \n",
        "\n",
        "**Voice:** Automatic Speech Recognition [Facebook's Wav2Vec2](https://huggingface.co/facebook/wav2vec2-base-960h)\n",
        "\n",
        "**Image:** Object Detection [DETR End-to-End Object Detection model with ResNet-50 backbone](https://huggingface.co/facebook/detr-resnet-50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vqq4sZ4Qb8me"
      },
      "source": [
        "## Let's Run Pretrained Models for Predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpvE1ionWmLy"
      },
      "source": [
        "The [pipeline()](https://huggingface.co/docs/transformers/main/en/main_classes/pipelines#transformers.pipeline) supports many common tasks out-of-the-box:\n",
        "\n",
        "**Text**:\n",
        "* Sentiment analysis: classify the polarity of a given text.\n",
        "* Text generation (in English): generate text from a given input.\n",
        "* Name entity recognition (NER): label each word with the entity it represents (person, date, location, etc.).\n",
        "* Question answering: extract the answer from the context, given some context and a question.\n",
        "* Fill-mask: fill in the blank given a text with masked words.\n",
        "* Summarization: generate a summary of a long sequence of text or document.\n",
        "* Translation: translate text into another language.\n",
        "* Feature extraction: create a tensor representation of the text.\n",
        "\n",
        "**Image**:\n",
        "* Image classification: classify an image.\n",
        "* Image segmentation: classify every pixel in an image.\n",
        "* Object detection: detect objects within an image.\n",
        "\n",
        "**Audio**:\n",
        "* Audio classification: assign a label to a given segment of audio.\n",
        "* Automatic speech recognition (ASR): transcribe audio data into text.\n",
        "\n",
        "<Tip>\n",
        "\n",
        "For more details about the [pipeline()](https://huggingface.co/docs/transformers/main/en/main_classes/pipelines#transformers.pipeline) and associated tasks, refer to the documentation [here](https://huggingface.co/docs/transformers/main/en/./main_classes/pipelines).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBYp9IOZDWNB"
      },
      "source": [
        "###Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BKkkyOlfcing"
      },
      "outputs": [],
      "source": [
        "#Sentiment Analysis\n",
        "from transformers import pipeline\n",
        "sent_classifier = pipeline(\"sentiment-analysis\")\n",
        "sent_classifier(\"I was pretty happy with the sneakers\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_J-cpP7C5Rr"
      },
      "outputs": [],
      "source": [
        "ARTICLE = \"\"\" New York (CNN)When Liana Barrientos was 23 years old, she got married in Westchester County, New York.\n",
        "A year later, she got married again in Westchester County, but to a different man and without divorcing her first husband.\n",
        "Only 18 days after that marriage, she got hitched yet again. Then, Barrientos declared \"I do\" five more times, sometimes only within two weeks of each other.\n",
        "In 2010, she married once more, this time in the Bronx. In an application for a marriage license, she stated it was her \"first and only\" marriage.\n",
        "Barrientos, now 39, is facing two criminal counts of \"offering a false instrument for filing in the first degree,\" referring to her false statements on the\n",
        "2010 marriage license application, according to court documents.\n",
        "Prosecutors said the marriages were part of an immigration scam.\n",
        "On Friday, she pleaded not guilty at State Supreme Court in the Bronx, according to her attorney, Christopher Wright, who declined to comment further.\n",
        "After leaving court, Barrientos was arrested and charged with theft of service and criminal trespass for allegedly sneaking into the New York subway through an emergency exit, said Detective\n",
        "Annette Markowski, a police spokeswoman. In total, Barrientos has been married 10 times, with nine of her marriages occurring between 1999 and 2002.\n",
        "All occurred either in Westchester County, Long Island, New Jersey or the Bronx. She is believed to still be married to four men, and at one time, she was married to eight men at once, prosecutors say.\n",
        "Prosecutors said the immigration scam involved some of her husbands, who filed for permanent residence status shortly after the marriages.\n",
        "Any divorces happened only after such filings were approved. It was unclear whether any of the men will be prosecuted.\n",
        "The case was referred to the Bronx District Attorney\\'s Office by Immigration and Customs Enforcement and the Department of Homeland Security\\'s\n",
        "Investigation Division. Seven of the men are from so-called \"red-flagged\" countries, including Egypt, Turkey, Georgia, Pakistan and Mali.\n",
        "Her eighth husband, Rashid Rajput, was deported in 2006 to his native Pakistan after an investigation by the Joint Terrorism Task Force.\n",
        "If convicted, Barrientos faces up to four years in prison.  Her next court appearance is scheduled for May 18.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJezrNIEBh6s"
      },
      "outputs": [],
      "source": [
        "summarizer = pipeline(\"summarization\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yOeWt-OxC5OV",
        "outputId": "a9284cdd-69a7-405c-e1b4-656cfaf26583"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'summary_text': ' Liana Barrientos has been married 10 times, nine of them between 1999 and 2002 . She is believed to still be married to four men, and at one time, she was married to eight men at once, prosecutors say . She pleaded not guilty at State Supreme Court in the Bronx on Friday .'}]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "summarizer(ARTICLE, max_length=130, min_length=30, do_sample=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SaEWTfmjcysx"
      },
      "outputs": [],
      "source": [
        "#Zero Shot Learning\n",
        "zero_shot = pipeline('zero-shot-classification')\n",
        "zero_shot(\n",
        "    \"This is a course about the Transformers library\",\n",
        "    candidate_labels=[\"education\", \"politics\", \"business\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3iwLYgdDd4-"
      },
      "source": [
        "###Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4uImYTfZC5Kr"
      },
      "outputs": [],
      "source": [
        "vision_classifier = pipeline(task=\"image-classification\")\n",
        "result = vision_classifier(\n",
        "    images=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg\"\n",
        ")\n",
        "print(\"\\n\".join([f\"Class {d['label']} with score {round(d['score'], 4)}\" for d in result]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RZA0oOhmsh5"
      },
      "source": [
        "## Finetuned FinBERT for Forward Looking Statements\n",
        "\n",
        "[FinBERT-FLS](https://huggingface.co/yiyanghkust/finbert-fls) is model developed for identifying Forward-looking statements (FLS). These statements inform investors of managers‚Äô beliefs and opinions about firm's future events or results. Identifying forward-looking statements from corporate reports can assist investors in financial analysis. FinBERT-FLS is a FinBERT model fine-tuned on 3,500 manually annotated sentences from Management Discussion and Analysis section of annual reports of Russell 3000 firms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rGyamloQmdxI"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification, pipeline\n",
        "\n",
        "finbert = BertForSequenceClassification.from_pretrained('yiyanghkust/finbert-fls',num_labels=3)\n",
        "tokenizer = BertTokenizer.from_pretrained('yiyanghkust/finbert-fls')\n",
        "nlp = pipeline(\"text-classification\", model=finbert, tokenizer=tokenizer)\n",
        "results = nlp('In the past, the age of our fleet to enhance availability and reliability due to reduced downtime for repairs.')\n",
        "print(results) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYA6nfG9BKPB"
      },
      "source": [
        "## Inference Pipelines from Hugging Face"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZhAaT_PZ6EF"
      },
      "source": [
        "For production use, you can use the [inference API](https://huggingface.co/inference-api) to get predictions via simple API calls.  To get the snippet, just go here\n",
        "![](https://i.ibb.co/P9yyTHg/Screen-Shot-2022-07-01-at-10-30-20-AM.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNWp4t5UBIc_"
      },
      "outputs": [],
      "source": [
        "# Example Snippet\n",
        "import requests\n",
        "\n",
        "API_URL = \"https://api-inference.huggingface.co/models/yiyanghkust/finbert-fls\"\n",
        "headers = {\"Authorization\": \"Bearer {API_TOKEN}\"}   ###Add your API Key here after Bearer\n",
        "\n",
        "def query(payload):\n",
        "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
        "\treturn response.json()\n",
        "\t\n",
        "output = query({\n",
        "\t\"inputs\": \"In the past, the age of our fleet to enhance availability and reliability due to reduced downtime for repairs.\",\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_8Q4GglDub2"
      },
      "source": [
        "# Extracting Information from Pre-trained Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "946BuwY9eLtE"
      },
      "source": [
        "[Embedding Model Used in the Presentation](https://huggingface.co/obrizum/all-MiniLM-L6-v2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BpdMF-fmBsdt"
      },
      "outputs": [],
      "source": [
        "sentences = [\"This is an example sentence\", \"Each sentence is converted\"]\n",
        "\n",
        "from sentence_transformers import SentenceTransformer, util, CrossEncoder\n",
        "\n",
        "model = SentenceTransformer('obrizum/all-MiniLM-L6-v2')\n",
        "embeddings = model.encode(sentences)\n",
        "print(embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdCNeJZSBtit"
      },
      "source": [
        "# Similarity Search\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhj65Rwae0l5"
      },
      "source": [
        "A great visualization tool for embeddings is the [Tensorflow Projector](https://projector.tensorflow.org/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHf7NRNmf6mP"
      },
      "source": [
        "[Similarity Model Used in the Presentation](https://huggingface.co/sentence-transformers/multi-qa-MiniLM-L6-cos-v1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXTaUijqgOVA"
      },
      "source": [
        "Let's use the concept of embeddings now to match a query with the best related passage in some documents. This demo will use an extract of Wikipedia as the passages to search."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJRD8mzZD_ss"
      },
      "outputs": [],
      "source": [
        "## Get Wikipedia data\n",
        "wikipedia_filepath = 'simplewiki-2020-11-01.jsonl.gz'\n",
        "\n",
        "if not os.path.exists(wikipedia_filepath):\n",
        "    util.http_get('http://sbert.net/datasets/simplewiki-2020-11-01.jsonl.gz', wikipedia_filepath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmFzmOJnD_qd",
        "outputId": "c41df69e-eba9-4b6a-d4e3-f0fc1573cac0",
        "collapsed": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Passages: 169597\n"
          ]
        }
      ],
      "source": [
        "passages = []\n",
        "with gzip.open(wikipedia_filepath, 'rt', encoding='utf8') as fIn:\n",
        "    for line in fIn:\n",
        "        data = json.loads(line.strip())\n",
        "\n",
        "        #Add all paragraphs\n",
        "        #passages.extend(data['paragraphs'])\n",
        "\n",
        "        #Only add the first paragraph\n",
        "        passages.append(data['paragraphs'][0])\n",
        "\n",
        "print(\"Passages:\", len(passages))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0j-U9BkE0-2",
        "outputId": "786c858b-8de3-41a3-c77d-af6c0009d783"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'id': '798870',\n",
              " 'paragraphs': ['The Seminole bat (\"Lasiurus seminolus\") is a type of bat in the family Vespertilionidae.',\n",
              "  'The Seminole bat is often confused with the red bat. The Seminole bat has a mahogany color with a frosted look because to white tipped dorsal hairs. They weigh around 12 grams. Females are larger than males.',\n",
              "  'The Seminole bat is found in the Southeastern United States. This includes Louisiana, Georgia, Alabama, Mississippi, South Carolina and parts of Texas, Tennessee, Arkansas and North Carolina. It has also been seen as far as Mexico. It is a migratory species. In the winter, it lives along the Gulf Coast, North and South Carolina, and southern Arkansas. In the summer, they migrate as far north as Missouri and Kentucky.',\n",
              "  'It prefers to live in forested areas. In winter, they are found to use leaf litter and Spanish moss as insulation in their roost sites.',\n",
              "  'Seminole bats are insectivores. They eat large amounts of Hymenoptera (ants, bees and wasps), Coleoptera (beetles), Lepidoptera (moths). They have also been shown to eat smaller amounts of Homoptera (cicadas) and Diptera (flies).'],\n",
              " 'title': 'Seminole bat'}"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6ZduxGEE4bq",
        "outputId": "a4cbfb44-d31d-4218-dab6-2704cf55050a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Ted Cassidy (July 31, 1932 - January 16, 1979) was an American actor. He was best known for his roles as Lurch and Thing on \"The Addams Family\".',\n",
              " 'Aileen Carol Wuornos Pralle (born Aileen Carol Pittman; February 29, 1956\\xa0‚Äì October 9, 2002) was an American serial killer. She was born in Rochester, Michigan. She confessed to killing six men in Florida and was executed in Florida State Prison by lethal injection for the murders. Wuornos said that the men she killed had raped her or tried to rape her while she was working as a prostitute.',\n",
              " \"A crater is a round dent on a planet. They are usually shaped like a circle or an oval. They are usually made by something like a meteor hitting the surface of a planet. Underground activity such as volcanoes or explosions can also cause them but it's not as likely.\",\n",
              " 'Store has several meanings:',\n",
              " 'Chinese New Year, known in China as the SpringFestival and in Singapore as the LunarNewYear, is a holiday on and around the new moon on the first day of the year in the traditional Chinese calendar. This calendar is based on the changes in the moon and is only sometimes changed to fit the seasons of the year based on how the Earth moves around the sun. Because of this, Chinese New Year is never on January1. It moves around between January21 and February20.']"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "passages[0:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pa5O7L2GD4b2"
      },
      "outputs": [],
      "source": [
        "#We use the Bi-Encoder to encode all passages, so that we can use it with sematic search\n",
        "bi_encoder = SentenceTransformer('multi-qa-MiniLM-L6-cos-v1')\n",
        "bi_encoder.max_seq_length = 256     #Truncate long passages to 256 tokens\n",
        "top_k = 32                          #Number of passages we want to retrieve with the bi-encoder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Bff7SgeEXS1"
      },
      "outputs": [],
      "source": [
        "\n",
        "# We encode all passages into our vector space. This takes about 5 minutes (depends on your GPU speed)\n",
        "corpus_embeddings = bi_encoder.encode(passages, convert_to_tensor=True, show_progress_bar=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bH3wxiOPFt1n"
      },
      "outputs": [],
      "source": [
        "query=\"What is the capital of the United States?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36bOslhVD_mc"
      },
      "outputs": [],
      "source": [
        "# Encode the query using the bi-encoder and find potentially relevant passages\n",
        "question_embedding = bi_encoder.encode(query, convert_to_tensor=True)\n",
        "question_embedding = question_embedding.cuda()\n",
        "hits = util.semantic_search(question_embedding, corpus_embeddings, top_k=top_k)\n",
        "hits = hits[0]  # Get the hits for the first query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N3pBMwLIF3us"
      },
      "outputs": [],
      "source": [
        "print(\"\\n-------------------------\\n\")\n",
        "print(\"Top-3 Bi-Encoder Retrieval hits\")\n",
        "hits = sorted(hits, key=lambda x: x['score'], reverse=True)\n",
        "for hit in hits[0:3]:\n",
        "    print(\"\\t{:.3f}\\t{}\".format(hit['score'], passages[hit['corpus_id']].replace(\"\\n\", \" \")))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DojWEZjZi8XC"
      },
      "source": [
        "For a more advanced similarity search, let's add a cross encoder for reranking. If you want to see a more thorough comparison against lexicon searching, check out [https://bit.ly/raj_semantic/](https://bit.ly/raj_semantic/)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afVCdmhPD_eY"
      },
      "outputs": [],
      "source": [
        "##Go add a Cross Encoder for Reranking\n",
        "cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
        "\n",
        "##### Re-Ranking #####\n",
        "# Now, score all retrieved passages with the cross_encoder\n",
        "cross_inp = [[query, passages[hit['corpus_id']]] for hit in hits]\n",
        "cross_scores = cross_encoder.predict(cross_inp)\n",
        "\n",
        "# Sort results by the cross-encoder scores\n",
        "for idx in range(len(cross_scores)):\n",
        "    hits[idx]['cross-score'] = cross_scores[idx]\n",
        "\n",
        "# Output of top-5 hits from re-ranker\n",
        "print(\"\\n-------------------------\\n\")\n",
        "print(\"Top-3 Cross-Encoder Re-ranker hits\")\n",
        "hits = sorted(hits, key=lambda x: x['cross-score'], reverse=True)\n",
        "for hit in hits[0:3]:\n",
        "    print(\"\\t{:.3f}\\t{}\".format(hit['cross-score'], passages[hit['corpus_id']].replace(\"\\n\", \" \")))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PR9faV2NWTrG"
      },
      "source": [
        "# Let's Build a Demo\n",
        "\n",
        "**Demos** of machine learning models are an increasingly important part of machine learning. Demos allow:\n",
        "\n",
        "* model developers to easily **present** their work to a wide audience\n",
        "* increase **reproducibility** of machine learning research\n",
        "* diverse users to more easily **identify and debug** failure points of models\n",
        "\n",
        "\n",
        "As a quick example of what we would like to build, check out the [Keras Org on Hugging Face](https://huggingface.co/keras-io), which includes a description card and a collection of Models and Spaces built by Keras community. Any Space can be opened in your browser and you can use the model immediately, as shown here: \n",
        "\n",
        "![](https://i.ibb.co/7y6DGjB/ezgif-5-cc52b7e590.gif)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0KzbU4lQtv3"
      },
      "source": [
        "## 1. Build Quick ML Demos in Python Using the Gradio Library"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlSs72oUQ1VW"
      },
      "source": [
        "`gradio` is a handy Python library that lets you build web demos simply by specifying the list of input and output **components** expected by your machine learning model. \n",
        "\n",
        "For more detail [see the docs](https://gradio.app/docs/)\n",
        "\n",
        "In addition to the input and output types, Gradio expects a third parameter, which is the prediction function itself. This parameter can be ***any* regular Python function** that takes in parameter(s) corresponding to the input component(s) and returns value(s) corresponding to the output component(s)\n",
        "\n",
        "Enough words. Let's see some code!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aE8aAbTL0uab"
      },
      "outputs": [],
      "source": [
        "#from sentence_transformers import SentenceTransformer, CrossEncoder, util\n",
        "#import torch\n",
        "##import pickle\n",
        "#import pandas as pd\n",
        "#import gradio as gr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "id": "Uc_Q6IK-0uWs",
        "outputId": "81f5999f-ab0b-46fa-c42c-3a894b185144"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://58549.gradio.app\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting, check out Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://58549.gradio.app\" width=\"900\" height=\"500\" allow=\"autoplay; camera; microphone;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import gradio as gr\n",
        "\n",
        "def search(query,top_k=100):\n",
        "    ans=[]\n",
        "    ##### Sematic Search #####\n",
        "    # Encode the query using the bi-encoder and find potentially relevant passages\n",
        "    question_embedding = bi_encoder.encode(query, convert_to_tensor=True)\n",
        "    hits = util.semantic_search(question_embedding, corpus_embeddings, top_k=top_k)\n",
        "    hits = hits[0]  # Get the hits for the first query\n",
        "    ##### Re-Ranking #####\n",
        "    # Now, score all retrieved passages with the cross_encoder\n",
        "    cross_inp = [[query, passages[hit['corpus_id']]] for hit in hits]\n",
        "    cross_scores = cross_encoder.predict(cross_inp)\n",
        "    # Sort results by the cross-encoder scores\n",
        "    for idx in range(len(cross_scores)):\n",
        "        hits[idx]['cross-score'] = cross_scores[idx]\n",
        "    hits = sorted(hits, key=lambda x: x['cross-score'], reverse=True)\n",
        "    for idx, hit in enumerate(hits[0:3]):\n",
        "        ans.append(passages[hit['corpus_id']])\n",
        "    return ans[0],ans[1],ans[2]\n",
        "\n",
        "iface = gr.Interface(fn=search, \n",
        "                     inputs=gr.Textbox(label=\"Query\"), \n",
        "                     outputs=[gr.Textbox(label=\"Answer 1\"),gr.Textbox(label=\"Answer 2\"),gr.Textbox(label=\"Answer 3\")])\n",
        "\n",
        "iface.launch(debug=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6Ek7cORgDkQ"
      },
      "source": [
        "## 2. Host the Demo (for free) on Hugging Face Spaces\n",
        "\n",
        "Once you made a Gradio demo, you can host it permanently on Hugging Spaces very easily:\n",
        "\n",
        "Here are the steps to that (shown in the GIF below):\n",
        "\n",
        "A. First, create a Hugging Face account if you do not already have one, by visiting https://huggingface.co/ and clicking \"Sign Up\"\n",
        "\n",
        "B. Once you are logged in, click on your profile picture and then click on \"New Space\" underneath it to get to this page: https://huggingface.co/new-space\n",
        "\n",
        "C. Give your Space a name and a license. Select \"Gradio\" as the Space SDK, and then choose \"Public\" if you are fine with everyone accessing your Space and the underlying code\n",
        "\n",
        "D. Then you will find a page that provides you instructions on how to upload your files into the Git repository for that Space. You may also need to add a `requirements.txt` file to specify any Python package dependencies.\n",
        "\n",
        "E. Once you have pushed your files, that's it! Spaces will automatically build your Gradio demo allowing you to share it with anyone, anywhere!\n",
        "\n",
        "![GIF](https://huggingface.co/blog/assets/28_gradio-spaces/spaces-demo-finalized.gif)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmMd2HDSj0st"
      },
      "source": [
        "Check out [Ask Wiki](https://huggingface.co/spaces/rajistics/Ask-Wiki) by rajistics \n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Pre-Trained Models and Semantic Search - Ask Wiki Notebook",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}