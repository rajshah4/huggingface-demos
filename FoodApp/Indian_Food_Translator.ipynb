{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gh6QOr-qO4Ym"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/huggingface/education-toolkit/blob/main/02_ml-demos-with-gradio.ipynb)\n",
        "\n",
        "\n",
        "Transformers Pipeline Demo Notebook\n",
        "\n",
        "üí° **Welcome!**\n",
        "\n",
        "This notebook is a self-contained way to start using widely known Open Source technologies (`transformers`, `gradio`, etc). The core use case is getting familiar with Transformers and building a web application. \n",
        "- This notebook can be found at [https://bit.ly/raj_food](https://bit.ly/raj_food)\n",
        "- The accompanying slides are at my github for [huggingface-demos](https://github.com/rajshah4/huggingface-demos/tree/main/FoodApp). \n",
        "- A version of the app in spaces, [Indian Food Translator app](https://huggingface.co/spaces/rajistics/Indian_food_translator).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lb65KY8VcSV8"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet git+https://github.com/huggingface/transformers.git \n",
        "!pip install --quiet gradio\n",
        "!pip install --quiet datasets\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkJmA-r5L0EB"
      },
      "source": [
        "# Tutorial: Using Pretrained Models and Building Demos with Gradio ‚ö° & Hugging Face ü§ó "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_Iv1CJZPekG"
      },
      "source": [
        "**Learning goals:** The goal of this tutorial is to learn How To\n",
        "\n",
        "1. Use pre-trained models from the transformers library and that are available on the Hugging Face Hub\n",
        "2. Building a web demo, [Indian Food Detector](https://huggingface.co/spaces/rajistics/Indian_food_translator)\n",
        "\n",
        "**Duration**: 45 minutes\n",
        "\n",
        "**Prerequisites:** Knowledge of Python and basic familiarity with machine learning \n",
        "\n",
        "**Author**: [Rajiv Shah](https://twitter.com/rajistics) (feel free to ping me with any questions about this tutorial) \n",
        "\n",
        "All of these steps can be done for free! All you need is an Internet browser and a place where you can write Python üë©‚Äçüíª"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-wtA32Tbfbd"
      },
      "source": [
        "# Let's Start by Exploring Tasks at Hugging Face Hub\n",
        "[Hugging Face Tasks](https://hf.co/tasks) \n",
        "\n",
        "---\n",
        "\n",
        "[Automated Speech Recognition](https://huggingface.co/tasks/automatic-speech-recognition)\n",
        "\n",
        "[Object Detection](https://huggingface.co/tasks/object-detection)\n",
        "\n",
        "[Summarization](https://huggingface.co/tasks/summarization)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vqq4sZ4Qb8me"
      },
      "source": [
        "## Let's Run Pretrained Models using Python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpvE1ionWmLy"
      },
      "source": [
        "The [pipeline()](https://huggingface.co/docs/transformers/main/en/main_classes/pipelines#transformers.pipeline) supports many common tasks out-of-the-box:\n",
        "\n",
        "**Text**:\n",
        "* Sentiment analysis: classify the polarity of a given text.\n",
        "* Text generation (in English): generate text from a given input.\n",
        "* Name entity recognition (NER): label each word with the entity it represents (person, date, location, etc.).\n",
        "* Question answering: extract the answer from the context, given some context and a question.\n",
        "* Fill-mask: fill in the blank given a text with masked words.\n",
        "* Summarization: generate a summary of a long sequence of text or document.\n",
        "* Translation: translate text into another language.\n",
        "* Feature extraction: create a tensor representation of the text.\n",
        "\n",
        "**Image**:\n",
        "* Image classification: classify an image.\n",
        "* Image segmentation: classify every pixel in an image.\n",
        "* Object detection: detect objects within an image.\n",
        "\n",
        "**Audio**:\n",
        "* Audio classification: assign a label to a given segment of audio.\n",
        "* Automatic speech recognition (ASR): transcribe audio data into text.\n",
        "\n",
        "<Tip>\n",
        "\n",
        "For more details about the [pipeline()](https://huggingface.co/docs/transformers/main/en/main_classes/pipelines#transformers.pipeline) and associated tasks, refer to the documentation [here](https://huggingface.co/docs/transformers/main/en/./main_classes/pipelines).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBYp9IOZDWNB"
      },
      "source": [
        "###Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BKkkyOlfcing"
      },
      "outputs": [],
      "source": [
        "#Sentiment Analysis\n",
        "from transformers import pipeline\n",
        "sent_classifier = pipeline(\"sentiment-analysis\")\n",
        "sent_classifier(\"I was pretty happy with the sneakers\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJezrNIEBh6s"
      },
      "outputs": [],
      "source": [
        "#Text Generation\n",
        "generator = pipeline(\"text-generation\")\n",
        "#generator(\"In this course, we will teach you how to\")\n",
        "generator(\"Once upon a time,\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3iwLYgdDd4-"
      },
      "source": [
        "###Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4uImYTfZC5Kr"
      },
      "outputs": [],
      "source": [
        "vision_classifier = pipeline(task=\"image-classification\")\n",
        "result = vision_classifier(\n",
        "    images=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg\"\n",
        ")\n",
        "print(\"\\n\".join([f\"Class {d['label']} with score {round(d['score'], 4)}\" for d in result]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Translation Model"
      ],
      "metadata": {
        "id": "7A2paz6EOZr9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SaEWTfmjcysx"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
        "#Background on the model: https://huggingface.co/facebook/nllb-200-distilled-600M\n",
        "#Get list of language codes: https://github.com/facebookresearch/flores/tree/main/flores200#languages-in-flores-200\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/nllb-200-distilled-600M\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"facebook/nllb-200-distilled-600M\")\n",
        "\n",
        "translator = pipeline('translation', model=model, tokenizer=tokenizer, src_lang=\"eng_Latn\", tgt_lang='guj_Gujr')\n",
        "\n",
        "translator(\"UN Chief says there is no military solution in Syria\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Language Codes:  \n",
        "ace_Arab - Acehnese (Arabic script)\n",
        "\n",
        "asm_Beng - Assamese\n",
        "\n",
        "bel_cyrl - Belarusian\n",
        "\n",
        "bod_Tibt - Standard Tibetan\n",
        "\n",
        "guj_Gujr - Gujarati\n",
        "\n",
        "kmr+Latn - Northern Kurdish\n",
        "\n",
        "tir_Ethi - Tigrinya\n",
        "\n",
        "yue_Hant - Yue Chinese\n"
      ],
      "metadata": {
        "id": "a3zpz5eilPeQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine Tuned Pretrained Models\n",
        "\n",
        "Their are thousands of models available that are trained for specific tasks. You can also [fine tune](https://huggingface.co/docs/transformers/training) pre-trained models on your own data to solve your particular tasks."
      ],
      "metadata": {
        "id": "gxyM_ztwdqx8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RZA0oOhmsh5"
      },
      "source": [
        "### Finetuned FinBERT for Forward Looking Statements\n",
        "\n",
        "[FinBERT-FLS](https://huggingface.co/yiyanghkust/finbert-fls) is model developed for identifying Forward-looking statements (FLS). These statements inform investors of managers‚Äô beliefs and opinions about firm's future events or results. Identifying forward-looking statements from corporate reports can assist investors in financial analysis. FinBERT-FLS is a FinBERT model fine-tuned on 3,500 manually annotated sentences from Management Discussion and Analysis section of annual reports of Russell 3000 firms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rGyamloQmdxI"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"yiyanghkust/finbert-fls\")\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"yiyanghkust/finbert-fls\")\n",
        "\n",
        "\n",
        "nlp = pipeline(\"text-classification\", model=model, tokenizer=tokenizer)\n",
        "results = nlp('In the past, the age of our fleet to enhance availability and reliability due to reduced downtime for repairs.')\n",
        "print(results) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYA6nfG9BKPB"
      },
      "source": [
        "## Inference Pipelines from Hugging Face"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZhAaT_PZ6EF"
      },
      "source": [
        "For production use, you can use the [inference API](https://huggingface.co/inference-api) to get predictions via simple API calls.  To get the snippet, just go here\n",
        "![](https://i.ibb.co/P9yyTHg/Screen-Shot-2022-07-01-at-10-30-20-AM.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNWp4t5UBIc_"
      },
      "outputs": [],
      "source": [
        "# Example Snippet\n",
        "import requests\n",
        "\n",
        "API_URL = \"https://api-inference.huggingface.co/models/yiyanghkust/finbert-fls\"\n",
        "headers = {\"Authorization\": \"Bearer {API_TOKEN}\"}   ###Add your API Key here after Bearer\n",
        "\n",
        "def query(payload):\n",
        "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
        "\treturn response.json()\n",
        "\t\n",
        "output = query({\n",
        "\t\"inputs\": \"In the past, the age of our fleet to enhance availability and reliability due to reduced downtime for repairs.\",\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Image Classification for Indian Food\n",
        "\n",
        "[Indian Food Detector](https://huggingface.co/rajistics/finetuned-indian-food) is a pretrained model available at the Hugging Face hub.  It was fined tuned using the [indian food dataset](https://huggingface.co/datasets/rajistics/indian_food_images)."
      ],
      "metadata": {
        "id": "c87wQvZ7hCaW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoFeatureExtractor, AutoModelForImageClassification\n",
        "extractor = AutoFeatureExtractor.from_pretrained(\"rajistics/finetuned-indian-food\")\n",
        "model = AutoModelForImageClassification.from_pretrained(\"rajistics/finetuned-indian-food\")"
      ],
      "metadata": {
        "id": "gU8SipmIeSvn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#let's get an image to test with using streaming option\n",
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"rajistics/indian_food_images\",split='test', streaming=True)"
      ],
      "metadata": {
        "id": "Y6nNEldEf30H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imagepic = next(iter(dataset))['image']\n",
        "imagepic"
      ],
      "metadata": {
        "id": "tKpcmmf8hY8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "inputs = extractor(images=imagepic, return_tensors=\"pt\")\n",
        "outputs = model(**inputs)\n",
        "logits = outputs.logits\n",
        "predicted_class_idx = logits.argmax(-1).item()\n",
        "print(\"Predicted class:\", model.config.id2label[predicted_class_idx])"
      ],
      "metadata": {
        "id": "93jCa4v7e8NR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "im_url = Image.open(requests.get('https://huggingface.co/rajistics/finetuned-indian-food/resolve/main/126.jpg', stream=True).raw)\n",
        "im_url"
      ],
      "metadata": {
        "id": "SgrNwGBA7ETt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = extractor(images=im_url, return_tensors=\"pt\")\n",
        "outputs = model(**inputs)\n",
        "logits = outputs.logits\n",
        "predicted_class_idx = logits.argmax(-1).item()\n",
        "print(\"Predicted class:\", model.config.id2label[predicted_class_idx])"
      ],
      "metadata": {
        "id": "bHQCWfxr7rTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PR9faV2NWTrG"
      },
      "source": [
        "# Let's Build a Demo\n",
        "\n",
        "**Demos** of machine learning models are an increasingly important part of machine learning. Demos allow:\n",
        "\n",
        "* model developers to easily **present** their work to a wide audience\n",
        "* increase **reproducibility** of machine learning research\n",
        "* diverse users to more easily **identify and debug** failure points of models\n",
        "\n",
        "\n",
        "As a quick example of what we would like to build, check out the [Keras Org on Hugging Face](https://huggingface.co/keras-io), which includes a description card and a collection of Models and Spaces built by Keras community. Any Space can be opened in your browser and you can use the model immediately, as shown here: \n",
        "\n",
        "![](https://i.ibb.co/7y6DGjB/ezgif-5-cc52b7e590.gif)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0KzbU4lQtv3"
      },
      "source": [
        "## 1. Build Quick ML Demos in Python Using the Gradio Library"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlSs72oUQ1VW"
      },
      "source": [
        "`gradio` is a handy Python library that lets you build web demos simply by specifying the list of input and output **components** expected by your machine learning model. \n",
        "\n",
        "For more detail [see the docs](https://gradio.app/docs/)\n",
        "\n",
        "In addition to the input and output types, Gradio expects a third parameter, which is the prediction function itself. This parameter can be ***any* regular Python function** that takes in parameter(s) corresponding to the input component(s) and returns value(s) corresponding to the output component(s)\n",
        "\n",
        "Enough words. Let's see some code!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Creating an Interface"
      ],
      "metadata": {
        "id": "lES_Lp2fjSyn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "def greet(name):\n",
        "    return \"Hello \" + name + \"!!\"\n",
        "\n",
        "demo = gr.Interface(fn=greet, inputs=\"text\", outputs=\"text\")\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "SyTIJSxZjNfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "gr.Interface.load(\"huggingface/facebook/fastspeech2-en-ljspeech\").launch();\n",
        "\n"
      ],
      "metadata": {
        "id": "SHpXFv-DjUu9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from PIL import Image\n",
        "\n",
        "##Image Classification\n",
        "from transformers import AutoFeatureExtractor, AutoModelForImageClassification\n",
        "extractor = AutoFeatureExtractor.from_pretrained(\"rajistics/finetuned-indian-food\")\n",
        "model = AutoModelForImageClassification.from_pretrained(\"rajistics/finetuned-indian-food\")\n",
        "\n",
        "def image_to_text(imagepic):\n",
        "  inputs = extractor(images=imagepic, return_tensors=\"pt\")\n",
        "  outputs = model(**inputs)\n",
        "  logits = outputs.logits\n",
        "  predicted_class_idx = logits.argmax(-1).item()\n",
        "  return (model.config.id2label[predicted_class_idx])\n",
        "\n",
        "##Translation\n",
        "#from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
        "#Get list of language codes: https://github.com/facebookresearch/flores/tree/main/flores200#languages-in-flores-200\n",
        "#modelt = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/nllb-200-distilled-600M\")\n",
        "#tokenizert = AutoTokenizer.from_pretrained(\"facebook/nllb-200-distilled-600M\")\n",
        "\n",
        "#def translation(text):\n",
        "#  translator = pipeline('translation', model=modelt, tokenizer=tokenizert, src_lang=\"eng_Latn\", tgt_lang='ron_Latn')\n",
        "#  output = translator(text)\n",
        "# return (output[0]['translation_text'])\n",
        "\n",
        "##Translation\n",
        "demo = gr.Blocks()\n",
        "with demo:\n",
        "    image_file = gr.Image(type=\"pil\")\n",
        "    b1 = gr.Button(\"Recognize Image\")\n",
        "    text = gr.Textbox()\n",
        "    b1.click(image_to_text, inputs=image_file, outputs=text)\n",
        "    #b2 = gr.Button(\"Translation\")\n",
        "    #out1 = gr.Textbox()\n",
        "    #b2.click(translation, inputs=text, outputs=out1)\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "YdGvfJH8jUno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6Ek7cORgDkQ"
      },
      "source": [
        "## 2. Host the Demo (for free) on Hugging Face Spaces\n",
        "\n",
        "Once you made a Gradio demo, you can host it permanently on Hugging Spaces very easily:\n",
        "\n",
        "Here are the steps to that (shown in the GIF below):\n",
        "\n",
        "A. First, create a Hugging Face account if you do not already have one, by visiting https://huggingface.co/ and clicking \"Sign Up\"\n",
        "\n",
        "B. Once you are logged in, click on your profile picture and then click on \"New Space\" underneath it to get to this page: https://huggingface.co/new-space\n",
        "\n",
        "C. Give your Space a name and a license. Select \"Gradio\" as the Space SDK, and then choose \"Public\" if you are fine with everyone accessing your Space and the underlying code\n",
        "\n",
        "D. Then you will find a page that provides you instructions on how to upload your files into the Git repository for that Space. You may also need to add a `requirements.txt` file to specify any Python package dependencies.\n",
        "\n",
        "E. Once you have pushed your files, that's it! Spaces will automatically build your Gradio demo allowing you to share it with anyone, anywhere!\n",
        "\n",
        "![GIF](https://huggingface.co/blog/assets/28_gradio-spaces/spaces-demo-finalized.gif)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check out the final version of the app that identifies Indian food in pictures and then translates the result into other languages, [Indian Food Translator](https://huggingface.co/spaces/rajistics/Indian_food_translator)"
      ],
      "metadata": {
        "id": "pQ6kH4Cf8j8-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4_2ZN1B98jkY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Indian Food Translator",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}